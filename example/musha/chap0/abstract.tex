\jabst{
近年、人工知能は、単なる情報サービスにとどまらず、医療、自動車、翻訳、その他多くの分野にまたがって活発に利用されている。
身近なセンサー類を用いた機械学習技術が普及する一方で、その高度なデータ処理に伴う消費電力の増大が懸念されている。
そこで、国立研究開発法人 新エネルギー・産業技術開発機構（NEDO）は2016年に「省電力AIエンジンと異種エンジン統合クラウドによる人工知能プラットフォーム」のプロジェクトをスタートさせた。
このプロジェクトでは、FPGA、GPU、メモリなどの異種ノードを多数接続した大規模システムFiC(Flow-in-Clowd)が開発されている。
多数の高速リンクを接続したFPGAボードであるFiC-SW1は、FiCシステム上でのスイッチノードとしての役割だけでなく、初期のシステムソフトウェア開発用テストベッドとしての役割もある。
本稿では、FiC-SW1ボードの構成を紹介し、ボードの計算性能、転送性能の予備評価を行った。そのために、
FiC-SW1ボード上のFPGAに畳み込みニューラルネットワーク（CNN）の畳み込み層を処理するアクセラレータを実装し評価した。
その結果、最適化を施していないアクセラレータでも一般的なCPUに比べて658倍高速化することに成功した。また、
通信時間に対する計算時間の比率は、2倍から10倍、最大で26倍になることがわかった。


%NEDOプロジェクト「省電力AIエンジンと異種エンジン統合クラウドによる人工知能
%  プラットフォーム」では、新規に開発する省エネ推論・学習コアとFPGAを高速
%低コストの光ネットワークで多数接続し、専用システムソフトウェアにより統合制御する
%Flow-in-Cloud (FiC)の開発を開始した。FiCで用いられるスイッチは、
%STDM(Static Time Division Multiplex)によりボード間にサーキットスイッチング
%ネットワークを構築することのできるFPGAボードで構成される。
%本稿では、FiC-SW1ボードの構成を紹介し、この上にConvolutional Neural Network(CNN)を
%実装した場合の計算性能、転送性能の予備評価を行う。
%評価の結果、計算時間が通信時間に比べ最大で約565倍になることがわかった。
%しかし、リソースの問題から実装するアクセラレータをクロスレイヤー化する必要がある。
}


