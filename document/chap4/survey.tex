\chapter{関連研究}
{
\label{chap:survey}

\subsection{マルチFPGAシステム}
複数のFPGAにより構築されるシステムとしてはMicrosoft社の提供するBing検索エンジンに利用されているCatapult\cite{catapult1st}が提案されている．
このシステムはデータセンター内のCPUにFPGAアクセラレータが接続されているだけではなくFPGAで２次元トーラスのネットワークを作ってノード間の通信も担っている．
FPGAではBing検索のランク計算部の処理を担っている．
通信方式はパケット交換方式なので回線交換を利用するFiCシステムとはこの点で異なる．

\subsection{CNNアクセラレータの研究}
FPGAやGPU，専用チップを用いたCNNアクセラレータには，メモリバンド幅によるボトルネックなども含め，複数の層の演算を行うことができる畳み込み演算のアクセラレータを実装した
研究\cite{optimized}がある．本研究の畳み込み演算器の実装はこの研究のループタイリングなどの技術を参考にしている．
またメモリアクセスがボトルネックや消費電力の増大につながるという問題点を解決すべく，圧縮した重みで効率よく畳み込み演算を行う専用チップの開発をした研究もある\cite{EIE}．
本研究では32bitの重みを利用した演算を行っているが圧縮した重みを利用することで認識精度を落とすことなく，メモリアクセスや通信遅延が改善されるという結果から
今後の研究で圧縮した重みを利用した演算器の実装は検討すべきである．

\subsection{GoogLeNetのFPGAによる実装}

\subsubsection{CaffeフレームワークのFPGA拡張とWinograd変換による3$\times$3畳み込み演算の高速化検討\cite{caffeinated}}
CNNのフレームワークとして有名なCaffeをFPGA設計でも利用できるようにOpenCLで拡張し，さらにWinograd変換を
利用したフィルタサイズが3$\times$3の畳み込み演算の高速化を検討し実装した．CPUやGPUに比べて，かえって処理に時間がかかるという結果になってしまったが
フレームワークをFPGA設計にも導入することでCNNアクセラレータの開発コストが下がり，さまざまなネットワークモデルをFPGAに実装することが容易になることが期待されている．

\subsubsection{リソース分割によるCNNアクセラレータの効率最大化に関する研究\cite{max}}
\cite{optimized}など先行研究の多くのFPGAを用いたCNNアクセラレータは，
畳み込み演算器(CLP: Convolutional Layer Processor)を１つしか持たない設計をしていることが多い．
しかし複数の畳み込み層でこのCLP単体を使いまわすと各層の入出力のサイズの違いにより，リソース使用量が低下してしまったり，何度も使いまわさなければいけなくなってしまう．
複数のCLPを実装することでリソース使用率を最大化することを目指し,ネットワークのサイズによる最適化を行った．
その結果，\cite{optimized}で実装した畳み込み演算器と比較して，
AlexNet\cite{alexnet}では3.8倍, SqueezeNet\cite{squeezenet}やGoogLeNet\cite{googlenet}ではそれぞれ2.2倍，2.0倍を達成した．
}