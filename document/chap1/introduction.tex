\chapter{序論}
{
    \label{chap:introducion}

    \section{本研究の背景}
    \label{sec:backgroud}
    人工知能と称される機械学習をベースにした技術は爆発的な普及を見せていて日夜，メディアで取り上げられるだけでなく，
    自動運転やスマートスピーカー，スマートフォン向けアプリケーションなど様々なシステムに取り込まれている．
    しかし，人工知能のさらなる普及にはその計算基盤が必要である．
    その中でも特に画像認識や物体検出などの分野で活躍する畳み込みニューラルネットワーク(CNN)はその計算の特性から
    汎用CPUでは効率よく演算処理ができない．インテルやNVDIAなど大手半導体メーカーを始めとしてGoogleやMicrsoftなども
    人工知能向け専用アクセラレータの開発に心血を注いでいる．
    各社，研究機関はGPU，ASIC，FPGAなど様々なデバイス，手法で高速化を図る．
    その中でもFPGAはその電力効率のよさ，開発周期の短さ，再構成可能であることから注目され研究がなされている．
    日本でも国立研究開発法人新エネルギー・産業技術開発機構(NEDO)は「省電力AIエンジンと異種エンジン統合クラウドによる人工知能プラットフォーム」と銘打ったプロジェクトで
    複数のFPGA，GPU，メモリなどの異種ノードを多数接続した大規模人工知能計算基盤Flow-in-Clowd(FiC)を開発している．
    このFiCはデータセンターなどに導入されるクラウドシステムである.主演算装置となる複数のGPUを複数のFPGAのスイッチノードに接続し，
    高速通信を行う．高機能スイッチノードととなるマルチFPGAは多数の高速リンクが接続され，FiCの高速通信のスイッチングの役割を担う．
    さらにこのマルチFPGAシステムはスイッチノードという役割に加え，AIエンジンとしての役割も担う．
    そこで本研究ではマルチFPGAシステムの試作ボードであるFiC-SW1を複数枚用いて，CNNのモデルであるGoogLeNetを実装し，評価を取った．

    \section{研究目的}
    \label{sec:purpose}
    本研究の目的はマルチFPGAシステム上にGoogLeNetを実装し，既存研究や汎用CPU，GPUに対して
    性能向上を目指すことである

    \section{本論文の構成}
    \label{sec:composition}
    \ref{chap:googlenet}章では実装対象であるGoogLeNetと畳込みニューラルネットワークの概要を説明する．
    \ref{chap:ficsw}章では本研究で用いるマルチFPGAシステムとそのプロジェクトの概要を紹介する．
    \ref{chap:survey}章では本研究に関連する先行研究について説明する．
    \ref{chap:parallel}章ではGoogLeNetの並列化手法について説明する．
    \ref{chap:implement}章では\ref{chap:parallel}での並列化を考慮した実装方法について説明する． 
    \ref{chap:eval}章では本研究の評価を行う． 
    \ref{chap:conclusion}では本論文の結論を述べる．
}

