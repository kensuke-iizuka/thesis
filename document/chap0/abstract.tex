\jabst{
    昨今，人工知能が最新技術のトレンドとして様々なメディアに取り上げられている．
    人工知能技術が組み込まれる自動運転，レコメンドシステム，自動翻訳などのサービスは日々の生活をより豊かにすると期待されている．
    人工知能技術を実現させる機械学習の中でも，画像認識や自然言語処理，物体検出などの分野で
    大きな貢献を果たしているニューラルネットワークは一躍注目されていて，研究開発が盛んに行われている．
    ニューラルネットワークの一種である畳み込みニューラルネットワーク(CNN: Convolutional Neural Network)は畳み込み演算を主な計算とする．
    CNNは認識精度向上を目指し様々なモデルが提案されているが
    年々その計算量が増加する傾向にあり，研究サイクルを早くする，データセンターでのアプリケーションとしての利用に耐えうる，
    高速化，電力性能向上が求められている．

    しかし，汎用プロセッサではその要求を満たすことができないので，各半導体メーカや研究機関は専用のアクセラレータの開発に取り組んでいる．
    日本でも国立研究開発法人新エネルギー・産業技術開発機構(NEDO)は
    「省電力AIエンジンと異種エンジン統合クラウドによる人工知能プラットフォーム」プロジェクトで
    複数のFPGA，GPU，メモリなどの異種ノードを多数接続した大規模計算基盤Flow-in-Clowd(FiC)を開発している．
    複数のFPGAは高機能スイッチノードとして多数の高速リンクが接続され，FiCの高速通信のスイッチングの役割を担う．
    FiCシステムにおいて主演算を行うのはGPUノードであるが，FPGAノードもスイッチを実装した上で
    余った計算資源を利用してAIエンジンとしての役割も担うことができる．
    本研究の目的はマルチFPGAシステムに2014年の国際画像認識コンペで最高精度をマークしたCNNモデルの1つであるGoogLeNetを実装し，評価することで
    GoogLeNetの高速化を図るとともに，マルチFPGAシステムの深層学習アクセラレータとしての活用ができるかを検討することである．
    GoogLeNetが持つネットワークモデル特有の計算並列性，畳込み演算の計算並列性を利用してマルチFPGAシステムへの実装を検討するとともに

    シュミレーション結果からCPUの〇〇倍の高速化を達成した．
}